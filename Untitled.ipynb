{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74630fdf-5b3f-4948-a7ad-b5de23270964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "989cf16f-6441-462c-a633-e5f8b9659895",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextUtils\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/evaluationserver/code/New_code/SmartLLM/helpers/text_utils.py:6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTextUtils\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m     curly_word_pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw*)}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     group_sub_pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m_!_@_(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+)_@_!_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/evaluationserver/code/New_code/SmartLLM/helpers/text_utils.py:45\u001b[0m, in \u001b[0;36mTextUtils\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroupdict()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplace_text\u001b[39m(\n\u001b[0;32m---> 45\u001b[0m     text: \u001b[38;5;28mstr\u001b[39m, replacements: \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m]\u001b[49m, curly_braces: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m ):\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    Replaces text in a string based on the given replacements dictionary.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m        Hello, {John}!\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m replacements\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from helpers.text_utils import TextUtils\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55db8c86-101d-40af-8f4b-dd3747196137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input={\"question\":\"\\u0935\\u0930\\u094d\\u0924\\u092e\\u093e\\u0928 \\u092e\\u0947\\u0902 \\u092d\\u093e\\u0930\\u0924 \\u092e\\u0947\\u0902 \\u0907\\u0932\\u0947\\u0915\\u094d\\u091f\\u094d\\u0930\\u093f\\u0915 \\u0935\\u093e\\u0939\\u0928\\u094b\\u0902 \\u092a\\u0930 \\u0915\\u094c\\u0928 \\u0938\\u0940 \\u0938\\u092c\\u094d\\u0938\\u093f\\u0921\\u0940 \\u0909\\u092a\\u0932\\u092c\\u094d\\u0927 \\u0939\\u0948\\u0902?\"}\n",
    "\n",
    "prompt_template = f\"\"\"\"<<SYS>> Being an honest and smart assistant talented in breaking down questions into actionable items, you're charged with interpreting a JSON-formatted question. Your output must be a JSON object articulated with two keys: can_i_answer (indicating true if the inquiry is answerable using internal capabilities, or false if it requires external resources) and tasks, delineating the series of steps to answer the question with external aids if can_i_answer is false. <<SYS>> [INST] {{'question': 'జలవనరుల నిర్వహణ మరియు పాదుకొనుగొలు ద్వారా వాతావరణ మార్పును ఎలా నివారించవచ్చు?'}} [/INST] \"\n",
    "\"\"\"\n",
    "\n",
    "# output=json.dumps({\"question\":\"\\u0935\\u0930\\u094d\\u0924\\u092e\\u093e\\u0928 \\u092e\\u0947\\u0902 \\u092d\\u093e\\u0930\\u0924 \\u092e\\u0947\\u0902 \\u0907\\u0932\\u0947\\u0915\\u094d\\u091f\\u094d\\u0930\\u093f\\u0915 \\u0935\\u093e\\u0939\\u0928\\u094b\\u0902 \\u092a\\u0930 \\u0915\\u094c\\u0928 \\u0938\\u0940 \\u0938\\u092c\\u094d\\u0938\\u093f\\u0921\\u0940 \\u0909\\u092a\\u0932\\u092c\\u094d\\u0927 \\u0939\\u0948\\u0902?\",\"tasks\":[\"RESEARCH: Find the latest government policies or subsidies for electric vehicles in India\",\"IDENTIFY: Determine which subsidy is the most beneficial\"],\"can_i_answer\":False})\n",
    "\n",
    "# actual_output=f\"{prompt_template}{output}</s>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "490be6e8-ca1b-4a05-8071-f14a2ed3573f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<<SYS>> Being an honest and smart assistant talented in breaking down questions into actionable items, you're charged with interpreting a JSON-formatted question. Your output must be a JSON object articulated with two keys: can_i_answer (indicating true if the inquiry is answerable using internal capabilities, or false if it requires external resources) and tasks, delineating the series of steps to answer the question with external aids if can_i_answer is false. <<SYS>> [INST] {'question': 'జలవనరుల నిర్వహణ మరియు పాదుకొనుగొలు ద్వారా వాతావరణ మార్పును ఎలా నివారించవచ్చు?'} [/INST] \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b9b35fd-841a-4b69-8eb6-7351f00c16f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvipinkatara/mLLM1_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(f\"{prompt_template=}\")\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_llm_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# start_string=decoded_output[0]+'{\"output\": '  \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# end_string=\"}\"+tokenizer.eos_token\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# response = TextUtils.get_middle_text(start_string, prompt, end_string).strip()\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/New_code/SmartLLM/infer/question_breaker.py:82\u001b[0m, in \u001b[0;36mget_llm_response\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     79\u001b[0m end_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39meos_token\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# print(f\"{end_string=}\")\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mTextUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_middle_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded_output\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_string\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m()\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# print(response)\u001b[39;00m\n\u001b[1;32m     84\u001b[0m response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "# prompt = get_prompt(input[\"question\"])\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vipinkatara/mLLM1_model\", device_map='auto')\n",
    "# print(f\"{prompt_template=}\")\n",
    "response = get_llm_response(prompt_template)\n",
    "# start_string=decoded_output[0]+'{\"output\": '  \n",
    "# end_string=\"}\"+tokenizer.eos_token\n",
    "\n",
    "# response = TextUtils.get_middle_text(start_string, prompt, end_string).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc42ae4-abe2-4cc6-b106-f5e25affcdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<SYS>> Being an honest and smart assistant talented in breaking down questions into actionable items, you're charged with interpreting a JSON-formatted question. Your output must be a JSON object articulated with two keys: can_i_answer (indicating true if the inquiry is answerable using internal capabilities, or false if it requires external resources) and tasks, delineating the series of steps to answer the question with external aids if can_i_answer is false. <<SYS>> [INST] {'question': 'वर्तमान में भारत में इलेक्ट्रिक वाहनों पर कौन सी सब्सिडी उपलब्ध हैं?'} [/INST] {\"question\": \"\\u0935\\u0930\\u094d\\u0924\\u092e\\u093e\\u0928 \\u092e\\u0947\\u0902 \\u092d\\u093e\\u0930\\u0924 \\u092e\\u0947\\u0902 \\u0907\\u0932\\u0947\\u0915\\u094d\\u091f\\u094d\\u0930\\u093f\\u0915 \\u0935\\u093e\\u0939\\u0928\\u094b\\u0902 \\u092a\\u0930 \\u0915\\u094c\\u0928 \\u0938\\u0940 \\u0938\\u092c\\u094d\\u0938\\u093f\\u0921\\u0940 \\u0909\\u092a\\u0932\\u092c\\u094d\\u0927 \\u0939\\u0948\\u0902?\", \"tasks\": [\"RESEARCH: Find the latest government policies or subsidies for electric vehicles in India\", \"IDENTIFY: Determine which subsidy is the most beneficial\"], \"can_i_answer\": false}</s>\n"
     ]
    }
   ],
   "source": [
    "print(actual_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3fcf9f-5302-443e-a140-255035626255",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41de9a8c-bbf8-472d-816a-9828518238a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=json.dumps({\"output\":{\"question\":\"\\u0935\\u0930\\u094d\\u0924\\u092e\\u093e\\u0928 \\u092e\\u0947\\u0902 \\u092d\\u093e\\u0930\\u0924 \\u092e\\u0947\\u0902 \\u0907\\u0932\\u0947\\u0915\\u094d\\u091f\\u094d\\u0930\\u093f\\u0915 \\u0935\\u093e\\u0939\\u0928\\u094b\\u0902 \\u092a\\u0930 \\u0915\\u094c\\u0928 \\u0938\\u0940 \\u0938\\u092c\\u094d\\u0938\\u093f\\u0921\\u0940 \\u0909\\u092a\\u0932\\u092c\\u094d\\u0927 \\u0939\\u0948\\u0902?\",\"tasks\":[\"RESEARCH: Find the latest government policies or subsidies for electric vehicles in India\",\"IDENTIFY: Determine which subsidy is the most beneficial\"],\"can_i_answer\":False}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22a4e46f-455c-42f6-8e6a-a38eb65d0d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"output\": {\"question\": \"\\\\u0935\\\\u0930\\\\u094d\\\\u0924\\\\u092e\\\\u093e\\\\u0928 \\\\u092e\\\\u0947\\\\u0902 \\\\u092d\\\\u093e\\\\u0930\\\\u0924 \\\\u092e\\\\u0947\\\\u0902 \\\\u0907\\\\u0932\\\\u0947\\\\u0915\\\\u094d\\\\u091f\\\\u094d\\\\u0930\\\\u093f\\\\u0915 \\\\u0935\\\\u093e\\\\u0939\\\\u0928\\\\u094b\\\\u0902 \\\\u092a\\\\u0930 \\\\u0915\\\\u094c\\\\u0928 \\\\u0938\\\\u0940 \\\\u0938\\\\u092c\\\\u094d\\\\u0938\\\\u093f\\\\u0921\\\\u0940 \\\\u0909\\\\u092a\\\\u0932\\\\u092c\\\\u094d\\\\u0927 \\\\u0939\\\\u0948\\\\u0902?\", \"tasks\": [\"RESEARCH: Find the latest government policies or subsidies for electric vehicles in India\", \"IDENTIFY: Determine which subsidy is the most beneficial\"], \"can_i_answer\": false}}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3734ff4-b489-4097-9036-68f3c5dd7371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe31bc8-3d91-464c-879f-26a9609e9ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'वर्तमान में भारत में इलेक्ट्रिक वाहनों पर कौन सी सब्सिडी उपलब्ध हैं?',\n",
       " 'tasks': ['RESEARCH: Investigate the current policies and subsidies for electric vehicles in India',\n",
       "  'ANALYZE: Determine which subsidies are available for electric vehicles and their eligibility criteria'],\n",
       " 'can_i_answer': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "115f7e5b-1302-41a8-b8c8-60b5d9ab7eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# Given input text\n",
    "text = '''Given the text, breakdown and generate a list of statements presented. Ambiguous statements and single words can also be considered as \n",
    "statements.\\n\\nExample:\\nExample text: Shoes. The shoes can be refunded at no extra cost. Thanks for asking the question!\\n\\n{\\n    \"statements\": [\"Shoes.\", \"Shoes can \n",
    "be refunded at no extra cost\", \"Thanks for asking the question!\"]\\n}\\n===== END OF EXAMPLE ======\\n        \n",
    "\\nText:\\n{\"question\":\"\\\\u0935\\\\u0930\\\\u094d\\\\u0924\\\\u092e\\\\u093e\\\\u0928 \\\\u092e\\\\u0947\\\\u0902 \\\\u092d\\\\u093e\\\\u0930\\\\u0924 \\\\u092e\\\\u0947\\\\u0902 \n",
    "\\\\u0907\\\\u0932\\\\u0947\\\\u0915\\\\u094d\\\\u091f\\\\u094d\\\\u0930\\\\u093f\\\\u0915 \\\\u0935\\\\u093e\\\\u0939\\\\u0928\\\\u094b\\\\u0902 \\\\u092a\\\\u0930 \\\\u0915\\\\u094c\\\\u0928 \\\\u0938\\\\u0940 \n",
    "\\\\u0938\\\\u092c\\\\u094d\\\\u0938\\\\u093f\\\\u0921\\\\u0940 \\\\u0909\\\\u092a\\\\u0932\\\\u092c\\\\u094d\\\\u0927 \\\\u0939\\\\u0948\\\\u0902?\",\"tasks\":[\"RESEARCH: Identify the current \n",
    "top-grossing movies worldwide\",\"ANALYZE: Determine which of these movies are categorized as action, adventure, or similar \n",
    "genres\"],\"can_i_answer\":false}\\n\\n**\\nIMPORTANT: Please make sure to only return in JSON format, with the \"statements\" key mapping to a list of strings. No words or \n",
    "explanation is needed.\\n**\\n\\nJSON:\\n[\\\\\"RESEARCH: Find the current top-grossing movies worldwide\\\\\",\\\\\"ANALYZE: Determine which of these movies are categorized as \n",
    "action, adventure, or similar genres\\\\\"],\\\\\"can_i_answer\\\\\":false}\"}</s>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c572ab-d1d1-4e98-9633-f6444059d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = re.search(r'Text:\\n(.*?)\\n\\n\\*\\*', text, re.DOTALL).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c638790-3646-4737-96a3-33ecbfaaf314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"question\":\"\\\\u0935\\\\u0930\\\\u094d\\\\u0924\\\\u092e\\\\u093e\\\\u0928 \\\\u092e\\\\u0947\\\\u0902 \\\\u092d\\\\u093e\\\\u0930\\\\u0924 \\\\u092e\\\\u0947\\\\u0902 \\n\\\\u0907\\\\u0932\\\\u0947\\\\u0915\\\\u094d\\\\u091f\\\\u094d\\\\u0930\\\\u093f\\\\u0915 \\\\u0935\\\\u093e\\\\u0939\\\\u0928\\\\u094b\\\\u0902 \\\\u092a\\\\u0930 \\\\u0915\\\\u094c\\\\u0928 \\\\u0938\\\\u0940 \\n\\\\u0938\\\\u092c\\\\u094d\\\\u0938\\\\u093f\\\\u0921\\\\u0940 \\\\u0909\\\\u092a\\\\u0932\\\\u092c\\\\u094d\\\\u0927 \\\\u0939\\\\u0948\\\\u0902?\",\"tasks\":[\"RESEARCH: Identify the current \\ntop-grossing movies worldwide\",\"ANALYZE: Determine which of these movies are categorized as action, adventure, or similar \\ngenres\"],\"can_i_answer\":false}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576cafd-44c3-45a9-a1a9-dd73d01968e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6deb57a6-5b86-4182-b4d0-70ba9084c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9520c0c-180a-4bef-bc42-f82d83190cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea0f304c3634b37bccbdee670bc226c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"vipinkatara/mLLM3_model\", device_map='auto', use_cache=False)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vipinkatara/mLLM3_model\", device_map='auto')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
